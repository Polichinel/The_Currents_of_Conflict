{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# C = 100 -> 6 obs  \n",
    "# C = 64 -> 12 obs  \n",
    "# C = 40 -> 38 obs  \n",
    "# C = 32 -> 60 obs  \n",
    "# C = 24 -> 87 obs  \n",
    "# C = 16 -> 158 obs\n",
    "# You still don't iterate over individual mean vs. common mean  "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from utils import get_views_coord\n",
    "from utils import test_val_train\n",
    "from utils import sample_conflict_timeline\n",
    "from utils import get_hyper_priors\n",
    "from utils import predict\n",
    "from utils import plot_predictions\n",
    "from utils import get_mse\n",
    "from utils import get_metrics\n",
    "\n",
    "import pymc3 as pm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict for the dfs/dicts holding the results\n",
    "eksperiments_dict = {}\n",
    "\n",
    "# minimum number of conf in timeslines predicted. C = 0 for full run\n",
    "C_pred = 32 \n",
    "#C_pred = 0\n",
    "\n",
    "N=None # if you want to sample a subset of the time lines drawn given c_est/C_pred\n",
    "seed = 42 # the random seed used if you set N != None\n",
    "dem = False # not sure this is in use..\n",
    "\n",
    "# minimum number of conf in timeslines used to est hyper parameters\n",
    "C_est_list = [64, 32, 16]\n",
    "\n",
    "# conflict type. Som might need lower c_est than 100 to work\n",
    "conf_type_list = ['ged_best_sb', 'ged_best_ns', 'ged_best_os', 'ged_best']\n",
    "\n",
    "# short term kernel\n",
    "s_kernel_list = ['ExpQuad', 'RatQuad', 'Matern32', 'Matern52']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Run for 9.16 minutes\n"
     ]
    }
   ],
   "source": [
    "for C_est in C_est_list:\n",
    "    for conf_type in conf_type_list:\n",
    "        for s_kernel in s_kernel_list:\n",
    "\n",
    "            print(f'{C_est}_{conf_type}_{s_kernel}\\n')\n",
    "\n",
    "            # Test cases:\n",
    "            #C_est = C_est_list[0]\n",
    "            #conf_type = conf_type_list[0]\n",
    "            #s_kernel = s_kernel_list[0]\n",
    "\n",
    "            # Start timer\n",
    "            start_time = time.time()\n",
    "\n",
    "            # get df:\n",
    "            # path = '/home/polichinel/Documents/Articles/conflict_prediction/data/ViEWS/'\n",
    "            path = '/home/polichinel/Documents/Articles/conflict_prediction/data/computerome_test/'\n",
    "            file_name = 'ViEWS_coord.pkl'\n",
    "            df = get_views_coord(path = path, file_name = file_name)\n",
    "\n",
    "            # get train and validation id:\n",
    "            train_id, val_id = test_val_train(df)\n",
    "\n",
    "            # get train (train + val) and test id:\n",
    "            # train_id, test_id = test_val_train(df, test_time = True)\n",
    "\n",
    "            # if you want to plot the hyper priors\n",
    "            # hyper_priors_dict = get_hyper_priors(plot = True)\n",
    "\n",
    "            # Constuction the gps and getting the map\n",
    "            hps = get_hyper_priors(plot = False)\n",
    "\n",
    "            with pm.Model() as model:\n",
    "\n",
    "                # short term trend/irregularities ---------------------------------\n",
    "\n",
    "                ℓ_s = pm.Gamma(\"ℓ_s\", alpha=hps['ℓ_alpha_s'] , beta=hps['ℓ_beta_s'])\n",
    "                η_s = pm.HalfCauchy(\"η_s\", beta=hps['η_beta_s'])\n",
    "\n",
    "                # mean func for short term trend\n",
    "                mean_s =  pm.gp.mean.Zero()\n",
    "\n",
    "                # cov function for short term trend\n",
    "                if s_kernel == 'ExpQuad': \n",
    "                    cov_s = η_s ** 2 * pm.gp.cov.ExpQuad(1, ℓ_s) \n",
    "\n",
    "                elif s_kernel == 'Matern32': \n",
    "                    cov_s = η_s ** 2 * pm.gp.cov.Matern32(1, ℓ_s) \n",
    "\n",
    "                elif s_kernel == 'Matern52': \n",
    "                    cov_s = η_s ** 2 * pm.gp.cov.Matern32(1, ℓ_s) \n",
    "\n",
    "                elif s_kernel == 'RatQuad': \n",
    "\n",
    "                    α_s = pm.Gamma(\"α_s\", alpha=hps['α_alpha_s'], beta=hps['α_beta_s']) \n",
    "                    cov_s = η_s ** 2 * pm.gp.cov.RatQuad(1, ℓ_s, α_s) # this seems to help alot when you split the trends below\n",
    "\n",
    "                # GP short term trend \n",
    "                gp_s = pm.gp.Marginal(mean_func = mean_s, cov_func=cov_s)\n",
    "\n",
    "\n",
    "                # long term trend -------------------------------------------------\n",
    "                ℓ_l = pm.Gamma(\"ℓ_l\", alpha=hps['ℓ_alpha_l'] , beta=hps['ℓ_beta_l'])\n",
    "                η_l = pm.HalfCauchy(\"η_l\", beta=hps['η_beta_l'])\n",
    "                \n",
    "                # mean and kernal for long term trend\n",
    "                mean_l =  pm.gp.mean.Zero()\n",
    "                cov_l = η_l **2 * pm.gp.cov.ExpQuad(1, ℓ_l) # Cov func.\n",
    "                \n",
    "                # GP short term trend \n",
    "                gp_l = pm.gp.Marginal(mean_func = mean_l, cov_func=cov_l)\n",
    "\n",
    "\n",
    "                # noise (constant \"white noise\") -----------------------------------\n",
    "                σ = pm.HalfCauchy(\"σ\", beta=hps['σ_beta'])\n",
    "\n",
    "\n",
    "                # sample and split X,y ---------------------------------------------  \n",
    "                X, y, _, _ = sample_conflict_timeline(conf_type = conf_type, df = df, train_id = train_id, test_id = val_id, C = C_est, N = None)\n",
    "\n",
    "                # Full GP ----------------------------------------------------------\n",
    "                gp = gp_s + gp_l\n",
    "\n",
    "                # sample:\n",
    "                for i in range(y.shape[1]):\n",
    "                    \n",
    "                    print(f'Time-line {i+1}/{y.shape[1]} in the works...') \n",
    "                    clear_output(wait=True)\n",
    "\n",
    "                    y_ = gp.marginal_likelihood(f'y_{i}', X=X[:,i][:,None], y=y[:,i], noise= σ)\n",
    "                    \n",
    "                \n",
    "                mp = pm.find_MAP()\n",
    "\n",
    "            # get alpha if you used the Rational Quadratic kernel for short term\n",
    "            if s_kernel == 'RatQuad':\n",
    "\n",
    "                map_df = pd.DataFrame({\n",
    "                    \"Parameter\": [\"ℓ_s\", \"η_s\", \"α_s\", \"ℓ_l\", \"η_l\", \"σ\"],\n",
    "                    \"Value at MAP\": [float(mp[\"ℓ_s\"]), float(mp[\"η_s\"]), float(mp[\"α_s\"]), float(mp[\"ℓ_l\"]), float(mp[\"η_l\"]), float(mp[\"σ\"])]\n",
    "                })\n",
    "\n",
    "            # if Exponentiated Quadratic og Matern kernel were used ignore alpha\n",
    "            else:\n",
    "\n",
    "                    map_df = pd.DataFrame({\n",
    "                    \"Parameter\": [\"ℓ_s\", \"η_s\", \"ℓ_l\", \"η_l\", \"σ\"],\n",
    "                    \"Value at MAP\": [float(mp[\"ℓ_s\"]), float(mp[\"η_s\"]), float(mp[\"ℓ_l\"]), float(mp[\"η_l\"]), float(mp[\"σ\"])]\n",
    "                }) \n",
    "\n",
    "            # Getting the predictions and merging with original df:\n",
    "            df_new = predict(conf_type = conf_type, df = df, train_id = train_id, test_id = val_id, mp = mp, gp = gp, gp_s = gp_s, gp_l = gp_l, σ=σ, C=C_pred)\n",
    "\n",
    "            df_merged = pd.merge(df_new, df[['id', 'pg_id','year','gwcode', 'xcoord', 'ycoord','ged_best_sb','ged_best_ns', 'ged_best_os', 'ged_best']], how = 'left', on = 'id') \n",
    "\n",
    "            # plot sanity check, but not if you have many time lines\n",
    "            # plot_predictions(df_merged = df_merged)\n",
    "\n",
    "            # getting mse results:\n",
    "            mse_resutls_df, mse_dict = get_mse(df_merged = df_merged, train_id = train_id, test_id = val_id)\n",
    "\n",
    "            # Creating devrivatives:\n",
    "            df_merged.sort_values(['pg_id', 'X'], inplace= True)\n",
    "            df_merged['mu_l_slope'] = df_merged.groupby('pg_id')['mu_l'].transform(np.gradient)\n",
    "            df_merged['mu_l_acc'] = df_merged.groupby('pg_id')['mu_l_slope'].transform(np.gradient)\n",
    "            df_merged['mu_l_mass'] = df_merged.groupby('pg_id')['mu_l'].transform(np.cumsum)\n",
    "            \n",
    "            # Get classification results\n",
    "            df_results = get_metrics(df_merged = df_merged, train_id = train_id, test_id = val_id)\n",
    "\n",
    "\n",
    "            # end timer\n",
    "            final_time = time.time()\n",
    "            final_run_time = final_time - start_time\n",
    "\n",
    "            string = f'Run for {final_run_time/60:.3} minutes'\n",
    "            print(string)\n",
    "\n",
    "            # \"filing\" names\n",
    "            pre_script_map_df = f'{C_est}_{conf_type}_{s_kernel}_map_df'\n",
    "            pre_script_mse_resutls_df = f'{C_est}_{conf_type}_{s_kernel}_mse_results_df'\n",
    "            pre_script_mse_dict = f'{C_est}_{conf_type}_{s_kernel}_mse_dict'\n",
    "            pre_script_df_results = f'{C_est}_{conf_type}_{s_kernel}_df_results'\n",
    "\n",
    "            # Save in the eksperiments_dict\n",
    "            eksperiments_dict[pre_script_map_df] = map_df\n",
    "            eksperiments_dict[pre_script_mse_resutls_df] = mse_resutls_df\n",
    "            eksperiments_dict[pre_script_mse_dict] = mse_dict\n",
    "            eksperiments_dict[pre_script_df_results] = df_results\n",
    "\n",
    "            # to only get one for testing\n",
    "            break\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"/home/polichinel/Documents/Articles/conflict_prediction/data/ViEWS/eksperiments_dict.pkl\"\n",
    "output = open(file_name, 'wb')\n",
    "pickle.dump(eksperiments_dict, output)\n",
    "output.close()"
   ]
  }
 ]
}